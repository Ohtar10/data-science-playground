{
    "collab_server" : "",
    "contents" : "# Temperature excercise for simple linear regression model\n\n# Import Rcommander\nlibrary(RcmdrMisc)\n\n# Load the data\nTemperature <- \n  readXL(\"./datasets/temperature.xlsx\", \n         rownames=FALSE, header=TRUE, na=\"\", sheet=\"Hoja1\", stringsAsFactors=TRUE)\n\n# A.1 Perform the scatterplot to see if there might be correlation\nscatterplot(Y.temperatura.en.ºC~X.altura.en.metros, reg.line=lm, smooth=FALSE, spread=FALSE,\n            boxplots=FALSE, span=0.5, ellipse=FALSE, levels=c(.5, .9), data=Temperature)\n\n# A.2 Perform the correlation matrix test, with pairwise p-value, look for a very small p-value in order to reject H0\nlibrary(lattice, pos=14)\nlibrary(survival, pos=14)\nlibrary(Formula, pos=14)\nlibrary(ggplot2, pos=14)\nlibrary(Hmisc, pos=14)\nrcorr.adjust(Temperature[,c(\"X.altura.en.metros\",\"Y.temperatura.en.ºC\")], type=\"pearson\", \n             use=\"complete\")\n\n# B Estimate the simple linear regression model\n# Statistics + Fit Model + Linear Regression\n# Pick X and Y from the data model\ntemperature_rm <- lm(Y.temperatura.en.ºC~X.altura.en.metros, data=Temperature)\nsummary(temperature_rm)\n# Pick the value for the Intercept B0 (28.924347)\n# Pick the value for the slope B1 (-0.009246)\n# So the proposed model so far is: y = 28.924347 -0.009246(x)\n\n# C.1 Interpretation: B0 is the expected temperature if we have x=0 (i.e. To the sea level we expect a temperature of 28.924347)\n# C.2 Interpretation: B1 For each meter gain in height, we expect temperature to go down by a mean of -0.009246\n\n# D Intepretation: Determination quotient: r^2: Multiple R-squared: 0.526, % of variability of the variable y explained by the model\n# This value should be close to 100% or 1, in this case 52.6% of the variability of the temperature is explained by the model i.e. the height in this case\n# The error explains the difference for r^2 to reach 1, so this model is not very good.\n# A good model is one that r^2 > 0.8 i.e the model explains great part of the variability of the temperature.\n\n# E, linear test i.e. variance analysis, H0: B0=B1=0 (i.e. the model simply doesn't work), H1: B0!=0 or B1!=0\n# Models + Hypothesis Test + ANOVA Table\nAnova(temperature_rm, type=\"II\")\n# ANOVA looks the variability of Y, it split it in 2.\n# Variability explained by the model 354.87, Variability by the error (residual) 319.77\n# With the above, the f-value is computed and then the p-value, which in this case is very small 4.099e-05, hence we reject H0\n\n# F, is the slope of the model statistically 0?\n# H0: B1=0, H1: B1=0\n# This is answered with the same command as question B, we should look at t value Pr(>|t|)\n# hence -5.052 4.10e-05, since p-value is so small, we can reject H0\n\n# G, is the intercept of the model statistically 0?\n# H0: B0=0, H1: B0=0\n# This is answered with the same command as question B, we should look at t value Pr(>|t|)\n# hence 10.763 1.88e-10, since p-value is so small, we can reject H0\n\n# Test of heteroscedasticity, Models + Numerical Diagnostics + Bresuch-Pagan, Variance of Errors\n# H0: V(ci) = Constant\n# H1: V(ci) != Constant\n# We should expect to get a constant variance of errors\n# In this case, \nlibrary(zoo, pos=19)\nlibrary(lmtest, pos=19)\nbptest(Y.temperatura.en.ºC ~ X.altura.en.metros, varformula = ~ \n         fitted.values(temperature_rm), studentize=FALSE, data=Temperature)\n\n# p-value is 0.0008998 which tell us that we should reject H0 so in this case we have a problem with the model\n# Graphically\noldpar <- par(oma=c(0,0,3,0), mfrow=c(2,2))\nplot(temperature_rm)\npar(oldpar)\n# Errors have a constant variance which is bad\n\n# Now we need to test the correlation of the errors\n# Models + Numerical Diagnosis + Durbin Watson\ndwtest(Y.temperatura.en.ºC ~ X.altura.en.metros, alternative=\"two.sided\", data=Temperature)\n# H0: the errors are not correlated, H1: the errors are correlated, we should ensure that we stick with H0\n# In this case p-value = 0.1521 so we should stick with H0, this is okay then\n\n# Perform a test of normallity over the errors\n# First add the errors to the dataset to perform analysis over this data, Models + Add observation statistics to data\nTemperature<- within(Temperature, {\n  residuals.temperature_rm <- residuals(temperature_rm) \n})\n# Then perform the normallity test, Statistics + summaries + test of normallity\nlibrary(nortest, pos=21)\nwith(Temperature, pearson.test(residuals.temperature_rm))\n\n# Then an Histogram\nwith(Temperature, Hist(residuals.temperature_rm, scale=\"frequency\", breaks=8, \n                       col=\"darkgray\"))\n\n# -----------------------------------------\n# This model failed a supposition, so we must do something else, for example, evaluate logarithms (ln or base 10) of X and Y\n# A common transformation function to normalize data is logarithms so we take the logarithm base 10 for X and Y\n# Add this to the dataset with, Data + Manage Variables + Compute Variable\nTemperature$log.Y <- with(Temperature, log(Y.temperatura.en.ºC))\nTemperature$log.X <- with(Temperature, log(X.altura.en.metros))\n# Infinite values should be changed to NA to avoid errors building the model again\n# The model should be reconstructed again and the suppositions should be evaluated again, if it fits, we can use this new model\n# and go back to the previous one performing the inverse operation of the logarithms\n# There might be other transformations worthy to test depending on the model type\n\n\n### look for transformations of box",
    "created" : 1497484540251.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1624057443",
    "id" : "A5998F00",
    "lastKnownWriteTime" : 1497489678,
    "last_content_update" : 1497489678685,
    "path" : "~/Data Science/Statistics/R-lab/temperature/temperature_regression.r",
    "project_path" : "temperature_regression.r",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}